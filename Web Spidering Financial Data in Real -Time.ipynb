{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROJECT\n",
    "\n",
    "### This is a project to scrap data from the web and store the results in both a text file as well as the SQLite database.\n",
    "\n",
    "\n",
    "#### The CNN Moneyâ€™s Market Movers website (https://money.cnn.com/data/hotstocks/ ) tracks the most active stocks on a real time basis. You will first write Python scripts that collect the list of Most Actives tickers only from the above website. Next, your programs should take these ticker symbols and build a comma separated text file (called stocks.txt) with data about each stock from the website: https://finance.yahoo.com/quote/AMD?p=AMD&.tsrc=fin-srch-v1 which gives the quote for ticker symbol AMD as an example. The data to be collected from the Yahoo Finance site should include (Actual text as seen in the website is in brackets):\n",
    "    OPEN price (Open)\n",
    "    AVERAGE VOLUME (Avg. Volume)\n",
    "    PE RATIO (PE Ratio (TTM))\n",
    "\n",
    "#### In addition to the stocks.txt file, the data should also be stored in an SQLite database called StocksDatabase in the directory that your Jupyter Notebook code will be executed from. The StocksDatabase should have a table called StocksTable that contains the following columns and types:\n",
    "    Ticker TEXT\n",
    "    OpenPrice REAL\n",
    "    AvgVolume INTEGER\n",
    "    PERatio REAL\n",
    "\n",
    "\n",
    "<font color = red>**Algorithm for the program :**</font>\n",
    "\n",
    "<font color = blue>Step - 1</font> Import from the url library the url handling modules also import re module and import sqlite3 module respectively <br>\n",
    "<font color = blue>Step - 2</font> Initiate try block and handle exceptions incase of web page is disruptive and create else statement for displaying the web scrapping program execution and completion message  <br>\n",
    "<font color = blue>Step - 3</font> Make a request to a web page using get method to send a get request to the specified url and then convert the html content to a text file <br>\n",
    "<font color = blue>Step - 4</font> In the text file using regex command re.findall and re.DOTALL pattern match with multiple lines span the Most active tickers and from those tickers further pattern match the ticker symbols <br>\n",
    "<font color = blue>Step - 5</font> Now in the new web page url with format() and a for loop iterate through the list of most active ticker symbols and send a get request to the specified active ticker url and then convert the html content to a text file  <br>\n",
    "<font color = blue>Step - 6</font> Create empty lists each for storing data to be used in textfile, database , also for each individual ticker url links and specific data to be collected from each of the most active tickers <br>\n",
    "<font color = blue>Step - 7</font> Inside the for loop using regex commands re.findall and re.DOTALL pattern match from each of the most active ticker web pages data and their respective Open Price , Average Volume and PE ratio and convert them to float, integer and using replace (), then append them into the empty list created for storing data specific to each most active ticker <br>\n",
    "### NOTE : We are assuming PE ratio with N/A values or no earnings as 0.0 Real Number for our program construct convenience\n",
    "<font color = blue>Step - 8</font> Data collected as list elements from specific most active tickers is then appened in other empty list created each for textfile and database constructs<br>\n",
    "<font color = blue>Step - 9</font> Create a CSV text file with textfile list elements by using join and map() and adding new line character at the end ,then open and create a text file named 'stocks.txt' and using writelines method write all list elements from the textfile list into the text file named 'stocks.txt' and then close the file <br>\n",
    "<font color = blue>Step - 10</font> Finally, with connection established with the SQLite database and the cursor we create a 'StocksDatabase.sqlite' database file and using SQL commands we Drop and create a Table named StocksTable and insert each Most active ticker's in TEXT and their specific stock values of OpenPrice in REAL, Average Volume in INTEGER and PE Ratio in REAL types respectively, using (execute, executemany for multiple inserts) and then we commit those records in the database and close both connections with the cursor and the SQLite database , this concludes the program  <br>\n",
    "\n",
    "### NOTE : In this program the execution takes a while , so please wait until program completion message is displayed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen                      # importing from the url library url handling modules\n",
    "import requests                                         # importing the requests module to send HTTP requests \n",
    "import re                                               # importing the re module to search a string for a match\n",
    "import sqlite3                                          # importing the sqlite3 module to perform SQL commands\n",
    "\n",
    "try:                                                    # beginning of try block              \n",
    "    hotstocks_url = 'https://money.cnn.com/data/hotstocks/' # web page url\n",
    "    hotstocks_fhand = requests.get(hotstocks_url)       # makes a request to a web page using get request to the specified url\n",
    "    hotstocks_text = hotstocks_fhand.text               # returns html content into a text file\n",
    "    \n",
    "    most_active = re.findall('<h3>Most Actives</h3>.*?</table>',hotstocks_text,re.DOTALL) # using regex commands do pattern matching for string\n",
    "    ticker_symbols = re.findall('class=\"wsod_symbol\">([^ <]*)',most_active[0])            # using regex commands pattern match most active ticker symbol\n",
    "    \n",
    "    ticker_url = 'https://finance.yahoo.com/quote/{urlticker}?p={urlticker}&.tsrc=fin-srch-v1' # web page url\n",
    "    print('Program is scraping data from the web......please wait!')# print statement to display beginning of the execution of the web scraping program\n",
    "    \n",
    "    textfile_list = []                                  # empty list for storing data to be appended into textfile\n",
    "    database_list = []                                  # empty list for storing data to be appended into database list\n",
    "   \n",
    "    for ticker in ticker_symbols:                       # for loop to iterate through each most active tickers list\n",
    "        mystocks_fhand = requests.get(ticker_url.format(urlticker = ticker)) # makes a get request for each ticker web page\n",
    "        mystocks_text = mystocks_fhand.text             # returns html content into a text file      \n",
    "        \n",
    "        ticker_link = []                                # empty list for storing html content from the web page \n",
    "        ticker_link = re.findall('OPEN-value.*?EPS',mystocks_text,re.DOTALL)# using regex commands pattern match and store the html content\n",
    "        stockdata = []                                  # empty list for storing data specific to each most active ticker   \n",
    "        stockdata.append(ticker)                        # appends each ticker into the empty list created as 0th element\n",
    "\n",
    "        data = re.findall('OPEN-value.*?([^ >]*)</span></td></tr>',ticker_link[0],re.DOTALL) # using regex commands pattern match openprice of the ticker\n",
    "        stockdata.append(float(data[0]))                #  convert numeric string character to float and append into stockdata list\n",
    "\n",
    "        data = re.findall('AVERAGE_VOLUME_3MONTH-value.*?([^ >]*)</span></td></tr>',ticker_link[0],re.DOTALL)# using regex commands pattern match avgvolume of the ticker\n",
    "        stockdata.append(int(data[0].replace(',','')))  # using replace() remove comma in string, convert numeric string character to integer and append into stockdata list\n",
    "        \n",
    "        data = re.findall('PE_RATIO-value.*?([^ >]*)</span></td></tr>',ticker_link[0],re.DOTALL)# using regex commands pattern match PEratio of the ticker\n",
    "        stockdata.append(float(data[0].replace('N/A','0.0')))# using replace () remove N/A in string, convert to assumed float value, append into stockdata list\n",
    "\n",
    "        database_list.append(stockdata)                      # appends respective stockdata lists in database list\n",
    "        textfile_list.append(((',').join(map(str,stockdata)))+'\\n')# creates a CSV file with list elements join using map() and add newline character at the end of each line\n",
    "    \n",
    "        fhand = open('stocks.txt','w')                  # opens stocks file in write mode\n",
    "        fhand.writelines(textfile_list)                 # writes all list elements into the text file   \n",
    "        fhand.close()                                   # closes the file \n",
    "       \n",
    "        conn = sqlite3.connect('StocksDatabase.sqlite') # connects or creates StocksDatabase in sqlite database\n",
    "        cur = conn.cursor()                             # initialize cursor and get cursor handle  \n",
    "\n",
    "        cur.execute('DROP TABLE IF EXISTS StocksTable') # drop StocksTable if it exists\n",
    "        cur.execute('CREATE TABLE StocksTable (Ticker TEXT, OpenPrice REAL, AvgVolume INTEGER, PERatio REAL)') # creates StocksTable with column names and types \n",
    "        cur.executemany('INSERT INTO StocksTable VALUES (?,?,?,?);',database_list)# insert all records/rows at once from database list\n",
    "        conn.commit()                                   # commit/write the record inserts into database\n",
    "        \n",
    "        cur.close()                                     # closes the current cursor object\n",
    "        conn.close()                                    # closes the connection to current database  \n",
    "    \n",
    "except:                                                 # raise an exception to catch URL error\n",
    "    print('Website is currently down. Please try again!')      \n",
    "else:                                                   # if try block doesn't raise an error this displays the program execution statement when it completes\n",
    "    print('The stocks.txt CSV File is created')\n",
    "    print('The StocksDatabase is created: Open in SQLite Browser')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
